---
title: 音视频从零到上手
date: 2022-02-20 02:01
tags: [音视频]
categories: [音视频]
---

# 音视频从零到上手

## 前言

从最初接手视频号负责发表业务，处理了很多和发表相关的case，但当时需求迭代很快，做完一个需求要做下一个需求，所以没有时间沉淀音视频压缩相关的功能，近期答辩结束打算将音视频相关的知识也做一下梳理。

此篇文章算是音视频的大纲，要知道音视频开发的流程是如何，每个环节可以用哪些趁手的工具，每个模块都值得深入学习。

（千万不要忽视音视频技术，想当初暴风影音靠一个播放器成为A股妖股还是很牛X的

## 移动端音视频路径

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzjc9sz89wj20ki0l340h.jpg)

### 推流、拉流

- 推流: 将手机采集到的视频数据传给后台播放端进行展示，播放端可以是windows, linux, web端，即手机充当采集的功能，将手机摄像头采集到视频和麦克风采集到的音频合成编码后传给对应平台的播放端。

- 拉流: 将播放端传来的视频数据在手机上播放,推流的逆过程，即将windows, linux, web端传来的视频数据进行解码后传给对应音视频硬件，最终将视频渲染在手机界面上播放.

从形式上来说，推流和拉流是互为逆过程，但在细节上并非如此（比如音视频同步都是倒数第二步）：

推流如下:

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzj7c1z01hj20t50ftmz4.jpg)

拉流如下：

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzj7c3h6erj20rr0k9jtf.jpg)

## 各步骤分析

### 1. 采集

采集是获取音视频的第一个环节：

- 音频原始数据格式为 PCM
- 视频原始数据格式为 YUV、RGB

#### 1.1 音频采集

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzj8li9184j21560gf0vb.jpg)

如果你不是专门做音频采集的需求，上图中你最高频可能遇到的是 Audio Session 这个类，这个类主要管理音频上下文，很多业务都需要处理音频冲突问题。

#### 1.2 视频采集

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzj8rzru2ij20o40fl0u7.jpg)

### 2. 处理

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzj91vmaarj20l20h8q4e.jpg)

### 3. 编码（重点在视频编码）

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzjcbk3046j20w40h2wh1.jpg)

说到视频编码，我们近期听到最多的可能就是 I帧，P帧，B帧，其实也就是以上 "运动估计和补偿" 的部分，因为 IPB 本身设计理念都非常有意思，所以我们这里展开说一下。

假设这是最开始的4帧：

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzjc0xc164j20w008owf2.jpg)

我们可以在帧内看到很多重复内容，如蓝色背景，从 0 帧到第 3 帧它都没有变化。为了解决这个问题，我们可以将它们抽象地分类为三种类型的帧。

（1）I 帧（帧内编码，关键帧）

I 帧（可参考，关键帧，帧内编码）是一个自足的帧。它不依靠任何东西来渲染，I 帧与静态图片相似。第一帧通常是 I 帧，但我们将看到 I 帧被定期插入其它类型的帧之间。

（2）P 帧（预测）

P 帧利用了一个事实：当前的画面几乎总能使用之前的一帧进行渲染。例如，在第二帧，唯一的改变是球向前移动了。仅仅使用（第二帧）对前一帧的引用和差值，我们就能重建前一帧。

https://tva1.sinaimg.cn/large/e6c9d24egy1gzjc246brnj20kw09gdg0.jpg

既然 P 帧使用较少的数据，为什么我们不能用单个 I 帧和其余的 P 帧来编码整个视频？（也就是说：是不是只靠I帧和P帧就够了？）

编码完这个视频之后，开始观看它，并快进到视频的末尾部分，你会注意到它需要花一些时间才真正跳转到这部分。这是因为 P 帧需要一个引用帧（比如 I 帧）才能渲染。

（3）B 帧（双向预测）

如何引用前面和后面的帧去做更好的压缩？！简单地说 B 帧就是这么做的。

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzjc3lwby7j20u408wmxk.jpg)

附：在这个阶段比较重要的是 FFmpeg ，基本属于必学框架，其负责了 编解码 和 格式封装 等功能。

### 4. 传输协议

常用协议：RTMP

### 5. 解码

![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzjcvkcfc4j20g50axwf6.jpg)

#### 5.1 硬解码和软解码

硬件解码就是通过显卡的视频加速功能对高清视频进行解码。因此硬解码能够将CPU从繁重的视频解码运算中释放出来，使播放设备具备流畅播放高清视频的能力。显卡的GPU/VPU要比CPU更适合这类大数据量的、低难度的重复工作。视频解码工作从处理器那里分离出来，交给显卡去做，这就叫做“硬解码”。

与之对应的，以前纯粹依靠CPU来解码的方式则是“软解码”。软解码是在显卡本身不支持或者部分不支持硬件解码的前提下，将解压高清编码的任务交给CPU，这是基于硬件配置本身达不到硬解压要求的前提下，属于一个折中的无奈之举。

对于一个超级电视而言，观看高清电影无疑是用户最大的诉求，而硬解码的优势就在于可以流畅的支持1080p甚至4K清晰度的电影播放，而不需要占用CPU，CPU就可以如释重负，轻松上阵，承担更多的其他任务。如果通过软解码的方式播放高清电影，CPU的负担较重，往往会出现卡顿、不流畅的现象。

#### 5.2 硬解码

编码数据仅用于传输,无法直接渲染到屏幕上，我们可以利用 FFmpeg 解析文件中的编码的视频流，并将压缩视频数据(h264/h265)解码为指定格式(yuv,RGB)的视频原始数据，以渲染到屏幕上。

### 6. 音视频同步

1、PTS（Presentation Time Stamp）：即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。 

2、DTS（Decoding Time Stamp）：即解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。



------
**这个公众号会持续更新技术方案、关注业内技术动向，关注一下成本不高，错过干货损失不小。
↓↓↓**
![](https://tva1.sinaimg.cn/large/e6c9d24egy1gzzmv1p67mj21bi0hcwgh.jpg)

> 文章首发：http://www.wenwoha.com/?cat_id=5